<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>performance - Tag - Known, Unknown, Unknownable</title>
        <link>https://blog.unknowntpo.me/tags/performance/</link>
        <description>performance - Tag - Known, Unknown, Unknownable</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>e850506@gmail.com (unknowntpo)</managingEditor>
            <webMaster>e850506@gmail.com (unknowntpo)</webMaster><lastBuildDate>Sun, 05 Mar 2023 11:00:44 &#43;0800</lastBuildDate><atom:link href="https://blog.unknowntpo.me/tags/performance/" rel="self" type="application/rss+xml" /><item>
    <title>Understand false sharing with a simple example</title>
    <link>https://blog.unknowntpo.me/false-sharing/</link>
    <pubDate>Sun, 05 Mar 2023 11:00:44 &#43;0800</pubDate>
    <author>unknowntpo</author>
    <guid>https://blog.unknowntpo.me/false-sharing/</guid>
    <description><![CDATA[False Sharing The Problem of false sharing = Example: slice of counters Measure the performance with go bench Detect cache miss with linux perf Example Usage of padding in standard library: sync.Pool 1 2 3 4 5 6 7 type poolLocal struct { poolLocalInternal // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } ]]></description>
</item>
<item>
    <title>Use `sync.Pool` to reduce memory consumption</title>
    <link>https://blog.unknowntpo.me/syncpool/</link>
    <pubDate>Mon, 13 Feb 2023 18:50:03 &#43;0800</pubDate>
    <author>unknowntpo</author>
    <guid>https://blog.unknowntpo.me/syncpool/</guid>
    <description><![CDATA[Identifying the problem Our service is like a excel document datastore. and we use xorm as ORM framework, Everytime we need to get data from DB, we call session.Find(&amp;[]Author{}) with the slice of table beans, but this have a problem,
Memory allocation is very high So every time lots of clients try to download excel file, the memory consumption is too high, and downloadling excel file takes too long to complete.]]></description>
</item>
<item>
    <title>Optimize a PARTITION - SELECT query up to 60x faster</title>
    <link>https://blog.unknowntpo.me/idx-only-scan/</link>
    <pubDate>Sun, 12 Feb 2023 14:23:03 &#43;0800</pubDate>
    <author>unknowntpo</author>
    <guid>https://blog.unknowntpo.me/idx-only-scan/</guid>
    <description><![CDATA[This post demonstrates my experience of optimizing a PARTITION - SELECT query, and how I made it up to 60x faster.
Original Query and the use case Our App is a simple excel data version control system, the data is organized by project, key and data is stored in seperated table called dbKey and dbData .
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 create table dbKey ( id serial , project_id int, -- keys goes here -- NOTE: key can be 1.]]></description>
</item>
</channel>
</rss>
